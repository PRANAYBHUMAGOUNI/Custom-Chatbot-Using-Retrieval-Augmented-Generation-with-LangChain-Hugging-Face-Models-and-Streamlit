# Custom-Chatbot-Using-Retrieval-Augmented-Generation-with-LangChain-Hugging-Face-Models-and-Streamlit

This project implements a custom chatbot using Retrieval Augmented Generation (RAG) with LangChain, HuggingFace Transformers, FAISS vector store, and Streamlit. The chatbot leverages a local language model to answer user queries based on provided documents.

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
  - [Step 1: Prepare the Data](#step-1-prepare-the-data)
  - [Step 2: Create the Vector Store](#step-2-create-the-vector-store)
  - [Step 3: Connect the LLM and Vector Store](#step-3-connect-the-llm-and-vector-store)
  - [Step 4: Run the Chatbot](#step-4-run-the-chatbot)
- [Requirements](#requirements)
- [Customization](#customization)
- [Future Enhancements](#future-enhancements)
- [Acknowledgements](#acknowledgements)

## Overview

The custom chatbot is designed to answer questions by retrieving relevant information from a given set of documents and generating responses using a local language model. It uses:

- LangChain for handling the language model and prompts.
- HuggingFace Transformers for the language model and embeddings.
- FAISS as the vector store for efficient similarity search.
- Streamlit for the chatbot user interface.

## Features

- **Document Ingestion:** Load and process PDF documents.
- **Vector Store Creation:** Embed documents and store them in a FAISS vector store.
- **Retrieval Augmented Generation:** Retrieve relevant documents based on user queries.
- **Local Language Model:** Generate answers using a local LLM (google/flan-t5-large).
- **Streamlit Interface:** Interactive chatbot UI for user queries.
- **Session Management:** Maintain conversation history using Streamlit's session state.

## Project Structure
```
Custom_Chatbot_using_RAG/
├── data/
│ └── The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf
├── vectorstore/
│ └── db_faiss/
├── create_memory_for_llm.py
├── connect_memory_with_llm.py
├── custom_chatbot.py
├── requirements.txt
├── README.md
```

- `data/`: Directory containing the source PDF documents.
- `vectorstore/`: Directory where the FAISS vector store is saved.
- `create_memory_for_llm.py`: Script to process documents and create the vector store.
- `connect_memory_with_llm.py`: Script to connect the language model with the vector store and generate answers.
- `custom_chatbot.py`: Streamlit application for the chatbot interface.
- `requirements.txt`: Python dependencies for the project.

## Installation

### Steps

1. Clone the repository or download the project files.

2. Navigate to the project directory:
```
cd path/to/Custom_Chatbot_using_RAG
```

3. Set up a virtual environment (optional but recommended):
```
python -m venv venv
venv\Scripts\activate
```

4. Install the required packages:
```
pip install -r requirements.txt
```

## Usage

### Step 1: Prepare the Data

Place your PDF documents inside the `data/` directory. The script will process all PDF files in this directory.

### Step 2: Create the Vector Store

Run the script to process the documents, split them into chunks, generate embeddings, and save them in a FAISS vector store.
```
python create_memory_for_llm.py
```
This script performs the following:

- Loads PDF documents from the `data/` directory.
- Splits the text into chunks suitable for processing.
- Generates embeddings using `sentence-transformers/all-MiniLM-L6-v2`.
- Saves the embeddings in a FAISS vector store located at `vectorstore/db_faiss`.

### Step 3: Connect the LLM and Vector Store

Test the retrieval and generation pipeline by running:
```
python connect_memory_with_llm.py
```

The script:

- Loads the FAISS vector store.
- Sets up the local LLM (`google/flan-t5-large`).
- Prompts you to enter a query.
- Retrieves relevant document chunks based on your query.
- Generates an answer using the LLM and displays source documents.

### Step 4: Run the Chatbot

Launch the Streamlit chatbot application:
```
streamlit run custom_chatbot.py
```

This will start a local web server. Open the provided URL (usually `http://localhost:8501/`) in your web browser to interact with the chatbot.

The chatbot allows you to:

- Enter queries in a conversational interface.
- Receive answers generated by the LLM based on retrieved documents.
- View source documents used to generate the answer.

## Requirements

The project requires the following Python packages, specified in `requirements.txt`:
```
langchain>=0.0.273
langchain-core>=0.0.208
langchain-community>=0.0.34
huggingface_hub>=0.18.0
transformers>=4.33.0
sentence-transformers>=2.2.2
faiss-cpu>=1.7.4
python-dotenv>=1.0.0
streamlit>=1.25.0
```

Make sure all dependencies are installed correctly. If you encounter issues with `faiss-cpu`, ensure that your Python version and environment are compatible.

## Customization

- **Change the Language Model:** Update the model in the `load_llm()` function in `connect_memory_with_llm.py` and `custom_chatbot.py`. Make sure to install the necessary dependencies for the new model.

- **Modify the Prompt Template:** Adjust the `CUSTOM_PROMPT_TEMPLATE` variable in the scripts to change how the assistant behaves.

- **Adjust Text Splitting:** Modify the `chunk_size` and `chunk_overlap` parameters in the `create_chunks()` function in `create_memory_for_llm.py`.

- **Use Different Documents:** Add or remove PDF files in the `data/` directory to change the source documents.

## Future Enhancements

Here are some ideas for future improvements to enhance the chatbot's capabilities and user experience:

1. **Integrate a More Powerful Language Model**
   - Upgrade to a Larger Model: Use a more powerful local model like `google/flan-t5-xxl` or switch to models like GPT-3.5 or GPT-4 if API access is available.
   - Leverage Open-source Models: Integrate models like BLOOM or LLaMA for more advanced language understanding.

2. **Add Support for Additional Document Formats**
   - Support Other File Types: Extend document ingestion to include Word documents (`.docx`), text files (`.txt`), HTML pages, and more.
   - Web Scraping: Implement web scraping functionality to include content from specific websites.

3. **Implement Continuous Learning**
   - Feedback Mechanism: Allow users to provide feedback on the usefulness of the responses to improve the model over time.
   - Retraining: Implement mechanisms to retrain the model periodically based on new data or user interactions.

4. **Enhance the User Interface**
   - UI Improvements: Use a more sophisticated UI framework or enhance the Streamlit app with custom components and better styling.
   - Mobile Support: Ensure that the chatbot interface is responsive and works well on mobile devices.

5. **Deploy the Chatbot Online**
   - Cloud Deployment: Deploy the application to cloud platforms like AWS, Azure, or Heroku for broader accessibility.
   - Dockerization: Containerize the application using Docker to simplify deployment and scaling.

6. **Implement User Authentication and Profiles**
   - Authentication System: Add user authentication to secure the chatbot and personalize responses.
   - User Profiles: Store user preferences and history to provide a more personalized experience.

7. **Advanced Search and Filtering**
   - Metadata Filtering: Allow users to filter sources by date, author, or other metadata.
   - Similarity Threshold Adjustment: Provide options to adjust the similarity threshold for document retrieval.

8. **Multilingual Support**
   - Language Detection: Detect the language of the user query and respond accordingly.
   - Multilingual Models: Integrate multilingual models to support users from different linguistic backgrounds.

9. **Real-time Analytics and Monitoring**
    - Usage Analytics: Implement analytics to monitor user interactions, common queries, and performance metrics.
    - Dashboard: Create an admin dashboard to visualize analytics and manage the chatbot.

10. **Compliance and Privacy**
    - Data Privacy: Ensure that user data is handled securely and in compliance with data protection regulations.
    - Content Filtering: Implement content moderation to prevent the generation of inappropriate responses.

## Acknowledgements

- [LangChain](https://www.langchain.com/) for providing tools to build language model applications.
- [HuggingFace Transformers](https://huggingface.co/transformers) for pre-trained language models and tokenizers.
- [FAISS](https://github.com/facebookresearch/faiss) for efficient similarity search and clustering.
- [Streamlit](https://streamlit.io/) for the web application framework.
- [Sentence Transformers](https://www.sbert.net/) for easy-to-use BERT-based sentence embeddings.









